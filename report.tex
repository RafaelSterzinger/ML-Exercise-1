\documentclass[aspectratio=169]{beamer}

%
% Choose how your presentation looks.
%
% For more themes, color themes and font themes, see:
% http://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html
%
\mode<presentation>
{
  \usetheme{default}      % or try Darmstadt, Madrid, Warsaw, ...
  \usecolortheme{default} % or try albatross, beaver, crane, ...
  \usefonttheme{default}  % or try serif, structurebold, ...
  \setbeamertemplate{navigation symbols}{}
  \setbeamertemplate{caption}[numbered]
}

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{graphicx}

\addtobeamertemplate{navigation symbols}{}{%
    \usebeamerfont{footline}%
    \usebeamercolor[fg]{footline}%
    \hspace{1em}%
    \insertframenumber/\inserttotalframenumber
}

%FilePath
\def \plots {./plots/}


\title[Your Short Title]{Exercise 1 - Regression}
\author{Rafael Sterzinger, Christian Stippel, Fatjon Zogaj}
\institute{Machine Learning}
\date{18.11.2019}

\begin{document}

\AtBeginSection[]{
  \begin{frame}
  \vfill
  \centering
  \begin{beamercolorbox}[sep=8pt,center,shadow=true,rounded=true]{title}
    \usebeamerfont{title}\insertsectionhead\par
  \end{beamercolorbox}
  \vfill
  \end{frame}
}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{}
\frametitle{Ridge Regression}
\begin{itemize}
    \item Analyzing multiple regression data that suffer from multicollinearity
    \item Least squares unbiased, but variances are large
    \item Parameter: alpha
\end{itemize}
\end{frame}

\begin{frame}{}
\frametitle{k Nearest Neighbours}
\begin{itemize}
    \item Lazy Learning
    \item Sensitive to local structure of data
    \item Parameter: amount of neighbours, evaluation metric
\end{itemize}
\end{frame}

\begin{frame}{}
\frametitle{Decision Tree}
\begin{itemize}
    \item Does not need a lot of pre-processing
    \item Easy to visualize and interpret
    \item Can overfit easily
    \item Parameter: maximum depth, minimum samples at split, minimum samples at leaf
\end{itemize}
\end{frame}

\begin{frame}{}
\frametitle{Multi Layer Perceptron}
\begin{itemize}
    \item Feedforward Artificial Neural Network
    \item Needs computing power
    \item Parameter: Specific Layers, Activation Function
\end{itemize}
\end{frame}


\begin{frame}{}
\frametitle{Bike Sharing Performance Characteristics}
\begin{minipage}{0.45\textwidth}
\begin{itemize}
\item No missing values
\item Target value is amount of shared bikes [1,970]
\item Nominal values e.g. holiday, workingday, weathersit
\item Ordinal values e.g. season, weekday
\item Interval values e.g. yr, mnth, temp, etc.
\item Already normalized
\end{itemize}
\end{minipage}
\begin{minipage}{0.5\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/bike_sharing/hist1.png}
\end{minipage}
\end{frame}

\begin{frame}
\frametitle{Bike Sharing with Square Square Root}
\begin{minipage}{0.49\textwidth}
	\center Original Histogram
    \includegraphics[width=1.0\textwidth]{plots/bike_sharing/hist1.png}
\end{minipage}
\begin{minipage}{0.49\textwidth}
	\center Square square root transformed Histogram
    \includegraphics[width=1.0\textwidth]{plots/bike_sharing/hist2.png}
\end{minipage}
\end{frame}


\begin{frame}{}
\frametitle{Bike Sharing Correlation}
\begin{minipage}{0.3\textwidth}
\begin{itemize}
\item Correlation of numerical values
\item atemp correlates too strong with temp
\end{itemize}
\end{minipage}
\begin{minipage}{0.69\textwidth}
	\center Heatmap of numerical values
    \includegraphics[width=1.0\textwidth]{plots/bike_sharing/heatmap_numerical.png}
\end{minipage}
\end{frame}


\begin{frame}
\frametitle{Bike Sharing hour Attribute}
\begin{minipage}{0.3\textwidth}
	\begin{itemize}
	\item Hours give a lot of information
	\item Correlated with $\approx$ 0.4
	\end{itemize}
\end{minipage}
\begin{minipage}{0.69\textwidth}
	\center Hour Boxplots
	\includegraphics[width=1.0\textwidth]{plots/bike_sharing/hour_boxplot.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Bike Sharing Ridge Regression}
% TODO add list and boxplot for Attributes
\begin{minipage}{0.3\textwidth}
\begin{itemize}
\item ridge regression performs poorly
\item as good as linear regression
\end{itemize}
\end{minipage}
\begin{minipage}{0.69\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/bike_sharing/ridge_regression.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Bike Sharing Decision Tree}
\begin{minipage}{0.3\textwidth}
\begin{itemize}
\item  Gets worse with increasing depth
\end{itemize}
\end{minipage}
\begin{minipage}{0.69\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/bike_sharing/tree_regression.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Bike Sharing k Nearest Neighbours}
\center Correlated attributes perform much worse\\~\\
\begin{minipage}{0.49\textwidth}
    \center All Attributes
    \includegraphics[width=1.0\textwidth]{plots/bike_sharing/knn_all_attributes.png}
\end{minipage}
\begin{minipage}{0.49\textwidth}
    \center Top 5 Correlated
    \includegraphics[width=1.0\textwidth]{plots/bike_sharing/knn_correlation_regression.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Bike Sharing k Nearest Neighbours Using Encoded Time}
\begin{minipage}{0.3\textwidth}
Encoded attribute \textit{hr} into circular variables\
\begin{itemize}
\item $sin(2*\pi*x/24)$
\item $cos(2*\pi*x/24)$
\end{itemize}
Sadly there is no improvement
\end{minipage}
\begin{minipage}{0.69\textwidth}
  \includegraphics[width=1.0\textwidth]{plots/bike_sharing/knn_circular_time_regression.png}
\end{minipage}
 
\end{frame}


\begin{frame}{}
\frametitle{Bike Sharing Decision Trees }
Comparing minimum samples leaf and minimum samples split\\~\\
\begin{minipage}{0.49\textwidth}
	\center before transformation
    \includegraphics[width=1.0\textwidth]{plots/bike_sharing/tree_regression.png}
\end{minipage}
\begin{minipage}{0.49\textwidth}
	\center after transformation
    \includegraphics[width=1.0\textwidth]{plots/bike_sharing/tree_regression_transformed.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Bike Sharing MLP Transformed Comparison}

\begin{minipage}{0.49\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/bike_sharing/mlp_regression.png}
    \center Original
\end{minipage}
\begin{minipage}{0.49\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/bike_sharing/mlp_regression_transformed.png}
    \center Transformed
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Bike Sharing Summary}
\begin{table}[]
\begin{tabular}{ll}
\hline
\textbf{Technique}     & \textbf{Root Mean Squared Error} \\ \hline
Ridge Regression       &                  146                \\
k Nearest Neighbours   &                  35                \\
Decision Tree          &                39                  \\
Multi Layer Perceptron &              40                    \\ \hline
\end{tabular}
\end{table}
\end{frame}

\begin{frame}{}
\frametitle{Student Performance Characteristics}
\begin{minipage}{0.45\textwidth}
\begin{itemize}
\item No missing values
\item Categorical attributes
\item Lots of binary attributes
\item Target is in [0,20]
\end{itemize}
\end{minipage}
\begin{minipage}{0.5\textwidth}
    \includegraphics[width=1.0\textwidth]{\plots student_performance/grades_histogram.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Student Performance Comparing Father Job - Mother Job}
% TODO add list and boxplot for Attributes
\begin{minipage}{0.49\textwidth}
	\center Father Job
    \includegraphics[width=1.0\textwidth]{\plots student_performance/boxplot_father.png}
\end{minipage}
\begin{minipage}{0.49\textwidth}
	\center Mother Job
    \includegraphics[width=1.0\textwidth]{plots/student_performance/boxplot_mother.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Student Performance Correlation}
% TODO Heatmap
\begin{minipage}{0.3\textwidth}
\begin{itemize}
\item Picked 7 highest correlated ($> 0.1$)
\end{itemize}
\end{minipage}
\begin{minipage}{0.69\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/student_performance/heatmap_7_highest_numerical.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Student Performance Preprocessing}
% TODO
\begin{minipage}{0.99\textwidth}
\begin{itemize}
\item Data partly pre-processed (traveltime hours amount to [1:4])
\item One Hot Encoding
\item Binary Encoding
\item Normalization
\end{itemize}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Student Performance Ridge Regression}
% TODO add list and boxplot for Attributes
\begin{minipage}{0.49\textwidth}
    \center Original
    \includegraphics[width=1.0\textwidth]{plots/student_performance/ridge_alpha_comparison.png}
\end{minipage}
\begin{minipage}{0.49\textwidth}
    \center Normalized
    \includegraphics[width=1.0\textwidth]{plots/student_performance/ridge_alpha_comparison_normalized.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Student Performance k Nearest Neighbours}
\begin{minipage}{0.49\textwidth}
    \center Original
    \includegraphics[width=1.0\textwidth]{plots/student_performance/knn_k_comparison.png}
\end{minipage}
\begin{minipage}{0.49\textwidth}
    \center Normalized
    \includegraphics[width=1.0\textwidth]{plots/student_performance/knn_k_normalized_comparison.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Student Performance Decision Tree}
\begin{minipage}{0.3\textwidth}
\begin{itemize}
\item  Gets worse with increasing depth
\end{itemize}
\end{minipage}
\begin{minipage}{0.69\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/student_performance/tree_max_depth_comparison.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Student Performance Decision Tree }
\center Comparing minimum samples leaf and minimum samples split 
\begin{minipage}{0.49\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/student_performance/tree_min_samples_leaf_comparison.png}
\end{minipage}
\begin{minipage}{0.49\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/student_performance/tree_min_samples_split_comparison.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Student Performance MLP comparison}
\center Trying three different models, with Sigmoid, ReLU and Tangens
\begin{minipage}{0.49\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/student_performance/mlp_crossvalidation_layer_activation_function_comparison.png}
    \center Original
\end{minipage}
\begin{minipage}{0.49\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/student_performance/mlp_crossvalidation_layer_activation_function_comparison_normalized.png}
    \center Normalized
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Student Performance Summary}
\begin{table}[]
\begin{tabular}{ll}
\hline
\textbf{Technique}     & \textbf{Root Mean Squared Error} \\ \hline
Ridge Regression       &                  4.02                \\
k Nearest Neighbours   &                 3.9                 \\
Decision Tree          &                          3.8        \\
Multi Layer Perceptron &                4.2                  \\ \hline
\end{tabular}
\end{table}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{}
\frametitle{Online News Popularity Characteristics}
\begin{minipage}{0.3\textwidth}
\begin{itemize}
\item No missing values
\item 39797 instances
\item 61 attributes
\item Target value is number of shares in [15,1238]
\item Only nominal values
\end{itemize}
\end{minipage}
\begin{minipage}{0.69\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/online_news_popularity/recent_shares_histogram.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Online News Popularity Outlier Removal}
\begin{minipage}{0.3\textwidth}
\begin{itemize}
\item all Instances with $timedelta>30$
\item all Instances outside Interquartile Range
\end{itemize}
\end{minipage}
\begin{minipage}{0.69\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/online_news_popularity/outliers_recent_shares_histogram.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Online News Popularity Heatmap}
\begin{minipage}{0.3\textwidth}
\begin{itemize}
\item Only chose highest correlating attributes
\end{itemize}
\end{minipage}
\begin{minipage}{0.69\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/online_news_popularity/heatmap_highest_correlated.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Online News Popularity Ridge Regression}
\begin{minipage}{0.49\textwidth}
	\center original
    \includegraphics[width=1.0\textwidth]{plots/online_news_popularity/ridge_regression_alpha_comparison.png}
\end{minipage}
\begin{minipage}{0.49\textwidth}
	\center normalized
    \includegraphics[width=1.0\textwidth]{plots/online_news_popularity/ridge_regression_outliers_comparison.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Online News Popularity kNN}
\center
\begin{minipage}{0.69\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/online_news_popularity/knn_outliers_comparision_euclidean.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{Online News popularity Decision Tree}
\center
\begin{minipage}{0.69\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/online_news_popularity/tree_comparision_comparision.png}
\end{minipage}
\end{frame}


\begin{frame}{}
\frametitle{Online News Popularity MLP comparison}
\center Trying three different models, with Sigmoid, ReLU and Tangens
\begin{minipage}{0.49\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/online_news_popularity/mlp_comparision_top_correlating_recent.png}
    \center Original
\end{minipage}
\begin{minipage}{0.49\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/online_news_popularity/mlp_comparision_top_correlating_outlier.png}
    \center Normalized
\end{minipage}
\end{frame}


\begin{frame}{}
\frametitle{Online News Popularity Summary}
\begin{table}[]
\begin{tabular}{ll}
\hline
\textbf{Technique}     & \textbf{Root Mean Squared Error} \\ \hline
Ridge Regression       &                   988               \\
k Nearest Neighbours   &                 1000                 \\
Decision Tree          &                        1000          \\
Multi Layer Perceptron &             980                     \\ \hline
\end{tabular}
\end{table}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{}
\frametitle{CPU Performance Characteristics}
Interesting topic for computer science students. Very different to other data sets.
\begin{minipage}{0.3\textwidth}
\begin{itemize}
\item No missing values
\item Target value is estimated relative performance [15,1238]
\item Nominal values e.g. vendor, model
\item Rational values e.g. cycle time, cache
\item Not normalized
\end{itemize}
\end{minipage}
\begin{minipage}{0.69\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/cpu_performance/performance_histogram.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{CPU Performance Vendors}
\begin{minipage}{0.3\textwidth}
\begin{itemize}
\item Model number no information
\item Vendors are very unequal
\begin{itemize}
	\item Many vendors 1-2 chips
\end{itemize}
\end{itemize}
\end{minipage}
\begin{minipage}{0.69\textwidth}
    \includegraphics[width=1.0\textwidth]{plots/cpu_performance/vendor_histogram.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{CPU Performance Correlation}
\begin{itemize}
	\item All values are correlating with 0.3 or higher
	\item Selecting min/max main memory and cache
\end{itemize}
    \center \includegraphics[width=0.6\textwidth]{plots/cpu_performance/heatmap_numerical.png}
\end{frame}

\begin{frame}{}
\frametitle{CPU Performance Preprocessing}40
\begin{itemize}
\item Skewed data set
\item Mostly rational values
\item Preprocessing
\begin{itemize}
\item Remove outliers with z-score $>$ 3
\item Normalization
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{}
\frametitle{CPU Performance Ridge Regression}
Comparing all rational types with top three correlating values \\
Only with high alpha a minimum was reached \\ ~\\

\begin{minipage}{0.49\textwidth}
\center With outliers
   \includegraphics[width=1\textwidth]{plots/cpu_performance/ridge_comparision.png}
\end{minipage}
 \begin{minipage}{0.49\textwidth}
 \center Without outliers
   \includegraphics[width=1\textwidth]{plots/cpu_performance/ridge_comparision_outlier.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{CPU Performance Ridge Regression}
Comparing all rational types with top three correlating values\\Only with high alpha a minimum was reached
    \center \includegraphics[width=0.6\textwidth]{plots/cpu_performance/tree_comparision.png}
\end{frame}

\begin{frame}{}
\frametitle{CPU Performance K-Nearest Neighbors}
\center Only small K since data set is too small\\ ~\\
\begin{minipage}{0.49\textwidth}
\center With outliers
   \includegraphics[width=1\textwidth]{plots/cpu_performance/knn_comparision.png}
\end{minipage}
 \begin{minipage}{0.49\textwidth}
 \center Without outliers
   \includegraphics[width=1\textwidth]{plots/cpu_performance/knn_comparision_outlier.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{CPU Performance Decision Tree}
\center Comparing different metrics with all numerical values\\
\begin{minipage}{0.3\textwidth}
	\begin{itemize}
	\item Removing outliers has a big impact
	\end{itemize}
\end{minipage}
\begin{minipage}{0.69\textwidth}
  \center \includegraphics[width=1\textwidth]{plots/cpu_performance/tree_comparision_outlier.png}
\end{minipage}
\end{frame}

\begin{frame}{}
\frametitle{CPU Performance Multi-Layer Perceptron Outliers}
\center Trying three different models, with Sigmoid, ReLU and Tangens Hyperbolicus
    \center \includegraphics[width=0.6\textwidth]{plots/cpu_performance/mlp_regression.png}
\end{frame}

\begin{frame}{}
\frametitle{CPU Performance Multi-Layer Perceptron $\neg$ Outliers}
    \center \includegraphics[width=0.6\textwidth]{plots/cpu_performance/mlp_comparision_outlier.png}
\end{frame}






\begin{frame}{}
\frametitle{CPU Performance Summary}
\begin{table}[]
\begin{tabular}{ll}
\hline
\textbf{Technique}     & \textbf{Root Mean Squared Error} \\ \hline
Ridge Regression       &                  13.6                \\
k Nearest Neighbours   &              8                    \\
Decision Tree          &                15                  \\
Multi Layer Perceptron &             15                     \\ \hline
\end{tabular}
\end{table}
\end{frame}
\end{document}
